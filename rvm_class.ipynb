{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of the packages\n",
    "import numpy as np\n",
    "import scipy.optimize as optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.stats as sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterValueError(Exception):\n",
    "    \"\"\" Custom exception raised when a parameter has an invalid value.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RVM class\n",
    "class RVM:\n",
    "    \"\"\" Relevance Vector Machine (RVM)\n",
    "    \n",
    "    Implementation of RVM for both regression and classification.\n",
    "    \n",
    "    Attributes:\n",
    "        kerType: A string of the type of the desired kernel.\n",
    "        rvmType: A string denoting the RVM type to be used. The string \"EM\" denotes\n",
    "            an EM-like algorithm will be used to estimate the hyperparameters while\n",
    "            the string \"DD\" denotes the direct differentiation approach.\n",
    "        p: Integer value denoting the degree of the polynomial kernel.\n",
    "        sigma: Float value denoting the smoothing factor of the Gaussian kernel.\n",
    "        kappa: Float value denoting the scaling parameter of the sigmoid kernel.\n",
    "        delta: Float value denoting the translation parameter of the sigmoid kernel.\n",
    "        bTrained: boolean value which becomes true once the RVM has been trained.\n",
    "    \"\"\"\n",
    "\n",
    "    EPSILON = 1e-10\n",
    "    maxEpochs = 10000\n",
    "    \n",
    "    def __init__(self, kerType = 'poly', rvmType = \"EM\", p = 1, sigma = 1, \n",
    "                 kappa = 1, delta = 1):\n",
    "        \"\"\" Initializes the RVM class (constructor).\n",
    "        \n",
    "            Raises:\n",
    "                ParameterValueError: An error occured because a parameter had an\n",
    "                    invalid value.  \n",
    "        \"\"\"\n",
    "        # Check if the kernel type chosen is valid\n",
    "        kerTypes = ['linear', 'poly', 'radial', 'sigmoid']\n",
    "        if kerType not in kerTypes:\n",
    "            raise ParameterValueError(\"ParameterValueError: The string \" + kerType + \\\n",
    "                                       \" does not denote a valid kernel type\")\n",
    "        # Check if the string denoting the rvmType has a valid value\n",
    "        if rvmType != 'EM' and rvmType != 'DD':\n",
    "            raise ParameterValueError('ParameterValueError: ' + rvmType, \\\n",
    "                                       \" is not a valid RVM type value. Enter 'EM' or 'DD' as a value. \")\n",
    "       \n",
    "        self.kerType = kerType\n",
    "        self.rvmType = rvmType\n",
    "        self.p = p\n",
    "        self.sigma = sigma\n",
    "        self.kappa = kappa\n",
    "        self.delta = delta\n",
    "        self.bTrained = False\n",
    "\n",
    "    def kernel(self, x, y):\n",
    "        \"\"\" Kernel computation.\n",
    "        \n",
    "        It computes the kernel value based on the dot product\n",
    "        between two vectors.\n",
    "        \n",
    "        Args:\n",
    "            x: Input vector.\n",
    "            y: Other input vector.\n",
    "            \n",
    "        Returns:\n",
    "            The computed kernel value.\n",
    "        \"\"\"  \n",
    "        if self.kerType == \"linear\":\n",
    "            k = np.dot(x,y) + 1\n",
    "        elif self.kerType == \"poly\":\n",
    "            k = (np.dot(x,y) + 1) ** self.p\n",
    "        elif self.kerType == \"radial\":\n",
    "            k = math.exp(-(np.dot(x-y,x-y))/(2*self.sigma))\n",
    "        elif self.kerType == \"sigmoid\":\n",
    "            k = math.atanh(self.kappa * np.dot(x,y) - self.delta)\n",
    "\n",
    "        return k\n",
    "    \n",
    "    def getKernelMatrix(self, X):\n",
    "        \"\"\" Evaluates the kernel matrix K given a set of input samples.\n",
    "\n",
    "            Args:\n",
    "                X_tr: A NxM matrix with a M dimensional training input sample\n",
    "                    in each row.\n",
    "                \n",
    "            Returns:\n",
    "                An NxN Kernel matrix where N is the number of input samples.\n",
    "        \"\"\"\n",
    "        N = X.shape[0]\n",
    "        K = np.zeros((N, N))\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                K[i,j] = self.kernel(X[i], X[j])\n",
    "        return K\n",
    "\n",
    "    def getGammaValues(self, alpha_values, Sigma):\n",
    "        \"\"\"Evaluates the gamma values.\n",
    "        \n",
    "            Args:\n",
    "                alpha_values: N-dimensional vector with the hyperparameters of\n",
    "                    the marginal likelihood.\n",
    "                Sigma: NxN covariance matrix of the posterior\n",
    "                \n",
    "            Returns: A N-dimensional vector with the gamma values where \n",
    "                gamma_values[i] = 1 - alpha_values[i] * Sigma[i][i]\n",
    "        \"\"\"\n",
    "        N = alpha_values.shape[0]\n",
    "        gamma_values = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            gamma_values[i] = 1 - alpha_values[i] * Sigma[i][i]\n",
    "        return gamma_values\n",
    "        \n",
    "    def train(self, X_tr, Y_tr):\n",
    "        \"\"\" RVM training method\n",
    "        \n",
    "        Applies an EM-like algorithm or direct differentiation to estimate the\n",
    "        optimal hyperparameters (alpha and sigma) needed to make predictions\n",
    "        using the marginal likelihood.\n",
    "        \n",
    "        \n",
    "        Args:\n",
    "            X_tr: A matrix with a training input sample in each row.\n",
    "            Y_tr: A vector with the output values of each input sample\n",
    "                in X_tr.\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Get number of training data samples\n",
    "        N = X_tr.shape[0]\n",
    "        # Initialize the alpha values (weight precision values) and the A matrix\n",
    "        alpha_values = np.ones(N + 1)\n",
    "        A = np.diag(alpha_values)\n",
    "        # Initialize the sigma squared value and the B matrix\n",
    "        sigma_squared = 1\n",
    "        B = np.identity(N) * (sigma_squared ** -2)\n",
    "        # Calculate kernel matrix K and append a column with ones in the front (for the bias term??)\n",
    "        K = self.getKernelMatrix(X_tr)\n",
    "        K = np.hstack((np.ones(N).reshape((N, 1)), K))\n",
    "        # Calculate Sigma and mu based on the initialized parameters\n",
    "        Sigma = np.linalg.inv(K.T.dot(B).dot(K) + A)\n",
    "        mu = Sigma.dot(K.T).dot(B).dot(Y_tr)\n",
    "        # Calculate initial gamma values\n",
    "        gamma_values = self.getGammaValues(alpha_values, Sigma)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Approximate optimal hyperparameter values iteratively\n",
    "        next_alpha_values = np.zeros(N + 1)\n",
    "        for epoch in range(self.maxEpochs):\n",
    "            # Evaluate alpha values\n",
    "            for i in range(N + 1):\n",
    "                if self.rvmType == \"EM\":\n",
    "                    next_alpha_values[i] = 1 / (Sigma[i][i] + mu[i] ** 2)\n",
    "                elif self.rvmType == \"DD\":\n",
    "                    pass                \n",
    "            # Evaluate sigma value\n",
    "            next_sigma_squared = (np.linalg.norm(Y_tr - K.dot(mu)) ** 2) / (N - np.sum(gamma_values))\n",
    "            # Check if algorithm has converged\n",
    "            if (np.sum(np.absolute(next_alpha_values - alpha_values)) < self.EPSILON and\n",
    "                (next_sigma_squared - sigma_squared) < self.EPSILON):\n",
    "                    break\n",
    "            # If algorithm has not converged, update all the variables\n",
    "            alpha_values = next_alpha_values\n",
    "            sigma_squared = next_sigma_squared\n",
    "            Sigma = np.linalg.inv(K.T.dot(B).dot(K) + A)\n",
    "            mu = Sigma.dot(K.T).dot(B).dot(Y_tr)\n",
    "            gamma_values = self.getGammaValues(alpha_values, Sigma)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_tr = 50\n",
    "N_ts = 1000\n",
    "\n",
    "def trans(x):\n",
    "    N = np.shape(x)[0]\n",
    "    y = np.sin(x) + 3 + np.random.normal(loc=0, scale=0.1, size=N)\n",
    "    return y \n",
    "\n",
    "x_tr = np.linspace(0,7.5,num=N_tr)\n",
    "y_tr = trans(x_tr)\n",
    "x_ts = np.linspace(0,7.5,num=N_ts)\n",
    "y_ts = trans(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "[ 200.79180475  186.81550781  157.68442771  157.97751557  193.6186864\n",
      "  177.45152228  234.7208384   202.68187488  206.20478011  225.67309225\n",
      "  201.32685239  219.89547736  264.60644634  256.62431969  254.63050932\n",
      "  240.74345339  348.47591518  327.40923444  331.36294078  383.63794812\n",
      "  372.47254874  457.7569987   422.04580905  405.46582726  391.41849156\n",
      "  443.3042352   492.97269601  523.25051542  446.10990332  522.4861964\n",
      "  406.5092793   540.23384992  490.03569974  460.07158067  458.77340662\n",
      "  533.09457963  523.7292509   487.06679078  523.6783194   482.77736217\n",
      "  446.41348477  508.06217927  501.32744151  454.13332438  433.04518716\n",
      "  442.13050021  540.21591208  386.64123155  447.48026452  369.88209667\n",
      "  378.13106048]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s = RVM()\n",
    "    s.train(x_tr, y_tr)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
