{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sklearn.datasets as skdata\n",
    "import scipy.optimize as optimize\n",
    "import math\n",
    "import scipy.stats as sts\n",
    "import time\n",
    "from rvm_class import RVM_reg\n",
    "from svm_reg_class import SVM_reg\n",
    "from collections import deque\n",
    "from numpy import linalg\n",
    "from data_gen import genData\n",
    "dirData = 'Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolds(X, N = 5):\n",
    "    \"\"\" Seperates data in N folds preparing the data for N-fold CV.\n",
    "    \n",
    "    Args:\n",
    "        X: matrix with input data\n",
    "        N: number of folds\n",
    "        \n",
    "    Returns:\n",
    "        A list with N tuples. Each tuple has a list of indices for the training data\n",
    "        and a list of indices for the validation data..\n",
    "    \"\"\"\n",
    "    input_size = X.shape[0]\n",
    "    indices = [i for i in range(input_size)]\n",
    "    chunk_size = int(input_size / N)\n",
    "\n",
    "    fold_list = []\n",
    "    for i in range(N):\n",
    "        training_indices = []\n",
    "        for i in range(0, input_size - chunk_size, chunk_size):\n",
    "            training_indices.extend(indices[i:i + chunk_size])\n",
    "        validation_indices = indices[input_size - chunk_size: input_size]\n",
    "        fold_list.append((training_indices, validation_indices))\n",
    "        # Put validation data in the front so that it is training data on the next fold\n",
    "        indices = validation_indices + training_indices\n",
    "    return fold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparams(X, Y, params, model_type, N = 5, rvmType = \"EM\", svmType = 'C', kerType = \"radial\"):\n",
    "    \"\"\" Hyperparameter tuning using a grid search and N-fold CV.\n",
    "    \n",
    "    Args:\n",
    "        X: matrix with input data\n",
    "        Y: vector with output data\n",
    "        params: list of lists with the possible values for each parameter\n",
    "        model_type: name of the model to be used\n",
    "        N: number of folds\n",
    "        rvmType: type of rvm (EM,DD,SSBL) in case model_type is \"rvm\"\n",
    "        svmType: type of svm (C or V)\n",
    "        kerType: type of kernel\n",
    "        \n",
    "    Returns:\n",
    "        A tuple with the parameters that achieved the best performance.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    fold_indices = createFolds(X, N)\n",
    "    min_error = 1e+50\n",
    "    if model_type == \"svm_reg\":\n",
    "        C_idx, eps_idx, sigma_idx = (-1, -1, -1)\n",
    "        # For each combination of parameters\n",
    "        for idx1, C in enumerate(params[0]):\n",
    "            for idx2, epsilon in enumerate(params[1]):\n",
    "                for idx3, sigma in enumerate(params[2]):\n",
    "                    # Do N-fold CV\n",
    "                    error = 0\n",
    "                    try:\n",
    "                        for i in range(N):\n",
    "                            train_indices, val_indices = fold_indices[i]\n",
    "                            X_tr = X[train_indices]\n",
    "                            Y_tr = Y[train_indices]\n",
    "                            X_val = X[val_indices]\n",
    "                            Y_val = Y[val_indices]\n",
    "                            svm = SVM_reg(svmType = svmType, kerType = kerType, C = C, eps = epsilon,  sigma = sigma)\n",
    "                            svm.train(X_tr, Y_tr)\n",
    "                            Y_pred = svm.pred(X_val)\n",
    "                            error += np.sum(np.abs(Y_pred - Y_val)) / Y_val.shape[0]\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        continue\n",
    "\n",
    "                    if error / N < min_error:\n",
    "                        C_idx = idx1\n",
    "                        eps_idx = idx2\n",
    "                        sigma_idx = idx3\n",
    "                        min_error = error / N\n",
    "                \n",
    "        return (C_idx, eps_idx, sigma_idx)\n",
    "    elif model_type == \"rvm_reg\":\n",
    "        sigma_idx = -1\n",
    "        # For each gaussian kernel sigma\n",
    "        for idx1, sigma in enumerate(params[0]):\n",
    "            # Do N-fold CV\n",
    "            error = 0\n",
    "            try:\n",
    "                for i in range(N):\n",
    "                    train_indices, val_indices = fold_indices[i]\n",
    "                    X_tr = X[train_indices]\n",
    "                    Y_tr = Y[train_indices]\n",
    "                    X_val = X[val_indices]\n",
    "                    Y_val = Y[val_indices]\n",
    "                    rvm = RVM_reg(rvmType = rvmType, kerType = kerType, sigma = sigma)\n",
    "                    rvm.train(X_tr, Y_tr)\n",
    "                    Y_pred, error_var = rvm.pred(X_val)\n",
    "                    error += np.sum(np.abs(Y_pred - Y_val)) / Y_val.shape[0]\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            if error / N < min_error:\n",
    "                sigma_idx = idx1\n",
    "                min_error = error / N\n",
    "        return (sigma_idx, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTest(X,Y,X_tst,Y_tst,X_sv,Y_sv,eps, typeR = 'RVM'):\n",
    "    plt.plot(X,Y,'go')\n",
    "    plt.plot(X_tst, Y_tst, 'b')\n",
    "    plt.fill_between(X_tst, Y_tst-eps, Y_tst+eps, \\\n",
    "        facecolor='lightblue', interpolate=True, alpha=0.5)\n",
    "    plt.plot(X_sv, Y_sv, 'ko', markersize = 15, mfc = \"None\")\n",
    "    if typeR == 'RVM':\n",
    "        plt.legend(['Training points', \\\n",
    "                    'Regression', \\\n",
    "                    'RV', \\\n",
    "                    'Prediction Standard Deviation'])\n",
    "    else:\n",
    "        plt.legend(['Training points', \\\n",
    "                    'Regression', \\\n",
    "                    'SV', \\\n",
    "                    'Insensitive tube'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndTest(X_tr, Y_tr, X_tst, Y_tst, eps = 0.2, C = 1, sigma_SV = 1, sigma_EM = 1, sigma_DD = 1, sigma_BL = 1):\n",
    "    svm = SVM_reg(svmType = \"C\", kerType = \"radial\", C = C, \\\n",
    "                  eps = eps, sigma = sigma_SV)\n",
    "    rvmEM = RVM_reg(rvmType='EM', kerType='radial', sigma = sigma_EM)\n",
    "    rvmDD = RVM_reg(rvmType='DD', kerType='radial', sigma = sigma_DD)\n",
    "    rvmBL = RVM_reg(rvmType='SSBL', kerType='radial', sigma = sigma_BL)\n",
    "    print(rvmBL.INFINITY)\n",
    "    e_rvm_EM = 0\n",
    "    e_rvm_DD = 0\n",
    "    e_rvm_BL = 0\n",
    "    e_svm = 0\n",
    "    N_rv_EM = 0\n",
    "    N_rv_DD = 0\n",
    "    N_rv_BL = 0\n",
    "    N_svm = 0\n",
    "    Time_rvm_EM = 0\n",
    "    Time_rvm_DD = 0\n",
    "    Time_rvm_BL = 0\n",
    "    Time_svm = 0\n",
    "    N_tst = Y_tst.shape[0]\n",
    "    S = 1\n",
    "    for i in range(S):    \n",
    "        start = time.clock()\n",
    "        rvmEM.train(X_tr, Y_tr)\n",
    "        Time_rvm_EM += time.clock() - start\n",
    "        start = time.clock()\n",
    "        rvmDD.train(X_tr, Y_tr)\n",
    "        Time_rvm_DD += time.clock() - start\n",
    "        start = time.clock()\n",
    "        rvmBL.train(X_tr, Y_tr)\n",
    "        Time_rvm_BL += time.clock() - start\n",
    "        start = time.clock()\n",
    "        svm.train(X_tr, Y_tr)\n",
    "        Time_svm += time.clock() - start\n",
    "        pred_rvm_EM, ser_EM = rvmEM.pred(X_tst)\n",
    "        pred_rvm_DD, ser_DD = rvmDD.pred(X_tst)\n",
    "        pred_rvm_BL, ser_BL = rvmBL.pred(X_tst)\n",
    "        pred_svm = svm.pred(X_tst)\n",
    "        e_rvm_EM += np.sum(np.abs(pred_rvm_EM - Y_tst)) / N_tst\n",
    "        e_rvm_DD += np.sum(np.abs(pred_rvm_DD - Y_tst)) / N_tst\n",
    "        e_rvm_BL += np.sum(np.abs(pred_rvm_BL - Y_tst)) / N_tst\n",
    "        e_svm += np.sum(np.abs(pred_svm - Y_tst)) / N_tst\n",
    "        X_rv_EM, Y_rv_EM = rvmEM.getSV()\n",
    "        X_rv_DD, Y_rv_DD = rvmDD.getSV()\n",
    "        X_rv_BL, Y_rv_BL = rvmBL.getSV()\n",
    "        X_sv, Y_sv = svm.getSV()\n",
    "        N_rv_EM += np.shape(X_rv_EM)[0]\n",
    "        N_rv_DD += np.shape(X_rv_DD)[0]\n",
    "        N_rv_BL += np.shape(X_rv_BL)[0]\n",
    "        N_svm += np.shape(X_sv)[0]\n",
    "    maxErr = np.max([e_rvm_EM, e_rvm_DD, e_rvm_BL])\n",
    "    e_rvm_EM /= S\n",
    "    e_rvm_DD /= S\n",
    "    e_rvm_BL /= S\n",
    "    e_svm /= S\n",
    "    N_rv_EM /= S\n",
    "    N_rv_DD /= S\n",
    "    N_rv_BL /= S\n",
    "    N_svm /= S\n",
    "    Time_rvm_EM /= S\n",
    "    Time_rvm_DD /= S\n",
    "    Time_rvm_BL /= S\n",
    "    Time_svm /= S\n",
    "    print(\"Friedman 2\")\n",
    "    print(\"EM error: \" + str(e_rvm_EM))\n",
    "    print(\"DD error: \" + str(e_rvm_DD))\n",
    "    print(\"BL error: \" + str(e_rvm_BL))\n",
    "    print(\"SVM error: \" + str(e_svm))\n",
    "    print(\"EM Relevant vectors: \" + str(N_rv_EM))\n",
    "    print(\"DD Relevant vectors: \" + str(N_rv_DD))\n",
    "    print(\"BL Relevant vectors: \" + str(N_rv_BL))\n",
    "    print(\"SVM support vectors: \" + str(N_svm))\n",
    "    print(\"EM training time: \" + str(Time_rvm_EM))\n",
    "    print(\"DD training time: \" + str(Time_rvm_DD))\n",
    "    print(\"BL training time: \" + str(Time_rvm_BL))\n",
    "    print(\"SVM training time: \" + str(Time_svm))\n",
    "    if X_tr.ndim == 1:\n",
    "        printTest(X_tr, Y_tr, X_tst, pred_rvm_EM, X_rv_EM, \\\n",
    "          Y_rv_EM, ser_EM, typeR='RVM')\n",
    "        printTest(X_tr, Y_tr, X_tst, pred_rvm_DD, X_rv_DD, \\\n",
    "                  Y_rv_DD, ser_DD, typeR='RVM')\n",
    "        printTest(X_tr, Y_tr, X_tst, pred_rvm_BL, X_rv_BL, \\\n",
    "                  Y_rv_BL, ser_BL, typeR='RVM')\n",
    "        printTest(X_tr, Y_tr, X_tst, pred_svm, X_sv, \\\n",
    "                  Y_sv, eps, typeR='SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, Y_tr, X_tst, Y_tst = genData(\"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    }
   ],
   "source": [
    "trainAndTest(X_tr, Y_tr, X_tst, Y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
